\section{Conclusion}
In this report, we described a method for estimating the direction of motion based on high frequency and unscaled optic-flow measurements and its implementation on embedded hardware. With its low computational cost, at the expense of some minor approximations, this method enables the estimation of the direction of motion on hardware with limited resources. More importantly, as it relies on an iterative voting approach, this method exhibit high robustness to outliers and is easily scalable when it comes to finding a trade-off between accuracy and computational ovehead.

The efficiency of the method was first proven in simulation by synthetically generating optic-flow fields. The algorithm was also implemented on real hardware and assessed using a high precision motion capture system. Although the results show that improvements are required - such as adding further processing of the data (e.g. filtering, smoothing) - the method and its underlying approximations proved to be correct.

This method may benefit from an adapted size of the patch used by the Lucas-Kanade method depending on the distance to the center of camera. Moreover, the determination of the best estimate at each stage of the voting procedure may be improved using online clustering or averaging techniques so as to cope with competing bins. Similarly, we could consider refining the estimate from one frame to the other, building on the previous estimates or even other sensor measurements. Finally, besides improving the framework, the integration of the hardware on the drone would require the calibration of the camera frame with respect to the body frame of the robot. This latter procedure would typically entail the correlation (regression) of gyroscope measurements from the camera and the main board of the drone in order to estimation the transformation from one frame to the other. 